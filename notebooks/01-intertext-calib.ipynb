{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "significant-belly",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from collections import Counter\n",
    "from itertools import product\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(18012023)\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 0)\n",
    "\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import lxml.etree\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, \\\n",
    "                            precision_recall_curve, average_precision_score, \\\n",
    "                            roc_auc_score\n",
    "\n",
    "import seaborn as sb\n",
    "sb.set(font_scale=.6)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('grayscale')\n",
    "sb.set_style(\"white\")\n",
    "sb.set_palette(\"Greys_r\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['image.cmap'] = 'Greys_r'\n",
    "\n",
    "from matplotlib.font_manager import FontProperties\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.sans-serif'] = ['Roboto Condensed']\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "challenging-mayor",
   "metadata": {},
   "source": [
    "## Loading and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f60a6d9",
   "metadata": {},
   "source": [
    "We create a directory for saving the figures if required:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "292daa53",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_dir = '../figures'\n",
    "if not os.path.isdir(fig_dir):\n",
    "    os.mkdir(fig_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb71a27",
   "metadata": {},
   "source": [
    "We load the spreadsheet which holds the tabular overview of the annotated intertexts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advanced-valuable",
   "metadata": {},
   "outputs": [],
   "source": [
    "intertexts = pd.read_excel('../data/intertexts.xlsx')\n",
    "print(len(intertexts), 'annotated in total')\n",
    "intertexts.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e708ae8c",
   "metadata": {},
   "source": [
    "Each row documents one attestation of an intertext in a pair of texts, with for every instance:\n",
    "- an `ID`, which is not unique, becomes the same intertext can be attested multiple times (i.e. for different document pairs);\n",
    "- the title of the `source` text and the `target` text (one of the four texts considered: *Lantsloot van der Hagedochte*, *Moriaen*, *Riddere metter mouwen*, *Karel ende Elegast*). Note that the direction of the intertext (cf. source vs target) is not material in what follows;\n",
    "- the actual passage in the source and target text (`src-passage` and `trg-passage`) quoted in the referenced publication; in the XML data (see \"data/xml\") the suggested annotation has been encoded at the level of entire verse line;\n",
    "- the approximate length of the match expressed in the number of verse lines involved;\n",
    "- a bibliographical reference for the intertext (`biblio`);\n",
    "- potentially, some (informal) `remarks`, which can be safely disregarded.\n",
    "\n",
    "While this spreadsheet holds a useful overview, the intertexts have also been manually encoded in the XML files in the `data/xml` directory in this repository, using an `intertext` attribute at the verse level that holds the corresponding `ID` of the row in the spreadsheet. For instance, in the *Elegast*:\n",
    "\n",
    "```xml\n",
    "  <l n=\"13\" tokens=\"Crone draghen ende houden hof\" intertext=\"mor-ele-2\">\n",
    "    ...\n",
    "  </l>\n",
    "  <l n=\"14\" tokens=\"Om te meerderen sinen lof\" intertext=\"mor-ele-2\">\n",
    "    ...\n",
    "  </l>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f36e2f",
   "metadata": {},
   "source": [
    "We can plot the length distribution (in verse lines) of the intertexts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personal-nightlife",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sb.histplot(data=intertexts, x='verse-length', discrete=True)\n",
    "\n",
    "heights = [p.get_height() for p in ax.patches]\n",
    "\n",
    "for i, height in enumerate(heights):\n",
    "    x_pos = ax.patches[i].get_x() + ax.patches[i].get_width()/2\n",
    "    \n",
    "    ax.text(x_pos, height, \n",
    "            str(int(height)),\n",
    "            ha='center',\n",
    "            va='bottom')\n",
    "\n",
    "plt.xlabel('Lengte interteksten (in versregels)')\n",
    "plt.ylabel('Aantal')\n",
    "plt.savefig(f'{fig_dir}/Afb3.jpg', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434f48d9",
   "metadata": {},
   "source": [
    "The annotated intertexts are comparatively short (1-2 lines).\n",
    "\n",
    "Below, we plot the number of absolute intertexts available across all text pairs (which are far from symmetric):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assured-fortune",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = sorted(set(intertexts['source'].tolist() + intertexts['target'].tolist()))\n",
    "counts = np.zeros((len(titles), len(titles)))\n",
    "for _, row in intertexts.iterrows():\n",
    "    counts[titles.index(row['source']), titles.index(row['target'])] += 1\n",
    "    counts[titles.index(row['target']), titles.index(row['source'])] += 1\n",
    "np.fill_diagonal(counts, np.nan)\n",
    "counts[np.triu_indices(4)] = np.nan\n",
    "titles = [t.split()[0] for t in titles]\n",
    "counts = pd.DataFrame(counts, columns=titles, index=titles)\n",
    "counts = counts.iloc[1:, :-1]\n",
    "ax = sb.heatmap(counts, annot=True, cmap='Greys', cbar=False, linewidths=1, linecolor='white')\n",
    "ax.tick_params(left=False, bottom=False)\n",
    "for l in plt.gca().lines:\n",
    "    l.set_alpha(0.3)\n",
    "plt.savefig(f'{fig_dir}/Afb2.jpg', dpi=300);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neutral-shore",
   "metadata": {},
   "source": [
    "#### Load metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ad9fba",
   "metadata": {},
   "source": [
    "We now load the metadata at the level of the XML files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressing-constitution",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df = pd.read_excel('../data/metadata_corrected.xlsx')\n",
    "meta_df = meta_df[meta_df['exclude'] != 'x']\n",
    "meta_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ad9322",
   "metadata": {},
   "source": [
    "The principles behind this metdata were previously discussed in this paper:\n",
    "\n",
    "> Vandyck, Caroline & Kestemont, Mike, ‘Een auteur van formaat. Een attributie-onderzoek naar het oeuvre van de Limborch-dichter’. *Spiegel der letteren* 66:2 (2024), 111-167 [[doi]](https://doi.org/10.2143/SDL.66.2.3293546).\n",
    "\n",
    "Apart from the genre labels (which are of course fuzzy and difficult to assign), the appendix to this paper also documents the interpolations that we remove from the texts below and our selection and merging of the textual witness, if multiple are available for a specific work (see the \"exclude\" column). We parse the XML files, using the following utility functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "differential-portsmouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_verse_groups(verses, size=2, intertexts=False):\n",
    "    for i in range(len(verses) - (size - 1)):\n",
    "        if not intertexts:\n",
    "            yield ' / '.join(verses[i : i + size])\n",
    "        else:\n",
    "            its = Counter(verses[i : i + size])\n",
    "            if None in its:\n",
    "                yield None\n",
    "            elif len(its) > 1:\n",
    "                # special case where multiple intertexts \n",
    "                # are present in the sale verse group\n",
    "                yield 'overlap'\n",
    "            else:\n",
    "                yield list(its.keys())[0]\n",
    "\n",
    "def parse_xml(fn, rm_interpol=False):\n",
    "    try:\n",
    "        tree = lxml.etree.parse(fn)\n",
    "    except OSError:\n",
    "        print(f'- Could not load {fn}')\n",
    "        return None\n",
    "    \n",
    "    # we remove (non-authorial) interpolations from the XMLs:\n",
    "    # see the appendix to Vandyck & Kestemont (2024)\n",
    "    if rm_interpol:\n",
    "        for interpolation in tree.xpath(\"//interpolation\"):\n",
    "            interpolation.getparent().remove(interpolation)\n",
    "        \n",
    "    for line_node in tree.iterfind('.//l'):\n",
    "        try:\n",
    "            intertext_id = line_node.attrib['intertext']\n",
    "        except KeyError:\n",
    "            intertext_id = None\n",
    "        \n",
    "        tokens_ = line_node.attrib['tokens'].split()\n",
    "        lemmas_ = []\n",
    "        \n",
    "        lemma_tags = [l.text for l in line_node.iterfind('.//lemma')]\n",
    "        pos_tags = [p.text for p in line_node.iterfind('.//pos')]\n",
    "        \n",
    "        for lemma, pos in zip(lemma_tags, pos_tags):\n",
    "            for l, p in zip(lemma.split('+'), pos.split('+')):\n",
    "                    if p == 'n(prop)':\n",
    "                        lemmas_.append('n(prop)')\n",
    "                    else:\n",
    "                        lemmas_.append(l)\n",
    "    \n",
    "        yield tokens_, lemmas_, intertext_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2654d0d1",
   "metadata": {},
   "source": [
    "Some comments on this process:\n",
    "- By default, we extract (overlapping) groups of two consecutive lines;\n",
    "- When extracting intertexts, the iterator in `get_verse_groups` takes into account that, because of the sliding window approach, a verse group might yield an \"overlap\" if two intertexts are immediately adjacent;\n",
    "- The lemmas for proper nouns are masked by replacing them with an 'n(prop)' symbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cordless-training",
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUP_SIZE = 2\n",
    "\n",
    "titles, tokens, lemmas, intertexts = [], [], [], []\n",
    "\n",
    "for title, group in tqdm(sorted(meta_df.groupby('title'))):\n",
    "    work_tokens, work_lemmas, work_intertexts = [], [], []\n",
    "    \n",
    "    for id_ in sorted(group['id']):\n",
    "        for tok, lem, intertext_id in parse_xml(f'../data/xml/{id_}.xml'):\n",
    "            work_tokens.append(tok)\n",
    "            work_lemmas.append(lem)\n",
    "            work_intertexts.append(intertext_id)\n",
    "    \n",
    "    verse_tokens = [' '.join(v) for v in work_tokens]\n",
    "    verse_lemmas = [' '.join(v) for v in work_lemmas]\n",
    "\n",
    "    verse_group_tokens = list(get_verse_groups(verse_tokens, size=GROUP_SIZE))\n",
    "    verse_group_lemmas = list(get_verse_groups(verse_lemmas, size=GROUP_SIZE))\n",
    "    verse_group_intertexts = list(get_verse_groups(work_intertexts, size=GROUP_SIZE, intertexts=True))\n",
    "\n",
    "    tokens.extend(verse_group_tokens)\n",
    "    lemmas.extend(verse_group_lemmas)\n",
    "    intertexts.extend(verse_group_intertexts)\n",
    "    titles.extend([title] * len(verse_group_lemmas))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d89aef",
   "metadata": {},
   "source": [
    "We can now create a single, huge dataframe that has all the verse groups from the corpus, with a title, the original tokens, the lemmas (which we'll use for the matching) and the intertext which was annotated for them (if any):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animated-guitar",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(zip(titles, tokens, lemmas, intertexts), columns=('title', 'tokens', 'lemmas', 'intertext'))\n",
    "# we ignore verse groups with ambiguous intertexts:\n",
    "df = df[df['intertext'] != 'overlap']\n",
    "df[(df['title'] == 'Karel ende Elegast') & (~df['intertext'].isna())].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef6fa84",
   "metadata": {},
   "source": [
    "Below, we'll assign special weight to the rhyme words in texts, which often seem to have served as a special cue or additional trigger for recognizing intertexts in the past. We'll achieve by adding an extra column to our dataframe, that has just the verse-final lemmas of the rhyme words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statistical-medicine",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_rhyme_column(df):\n",
    "    rhyme_words = []\n",
    "    for lemmas in df['lemmas']:\n",
    "        rhymes = []\n",
    "        for verse in lemmas.split(' / '):\n",
    "            rhymes.append(verse.strip().split()[-1])\n",
    "        rhyme_words.append(' '.join(rhymes))\n",
    "    df['rhyme'] = rhyme_words\n",
    "    return df\n",
    "\n",
    "df = add_rhyme_column(df)\n",
    "df[(df['title'] == 'Karel ende Elegast') & (~df['intertext'].isna())].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developing-namibia",
   "metadata": {},
   "source": [
    "#### Intermezzo: example TF-IDF\n",
    "\n",
    "In the section below, we create the pedagogic example of the single example verse from *Karel ende Elegast*, illustrating the subsequent steps of:\n",
    "- vectorization to a vector of relative frequencies\n",
    "- rescaling the frequencies using the TF-IDF procedure\n",
    "- vectorizing (only) the lemmas in rhyme position\n",
    "- obtaining the final vector used for the retrieval system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alien-ghana",
   "metadata": {},
   "outputs": [],
   "source": [
    "small = df[df['title'] == 'Karel ende Elegast'].iloc[[20]]\n",
    "small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "brown-efficiency",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    return text.replace(' / ', ' ').lower().strip().split()\n",
    "\n",
    "vec = TfidfVectorizer(max_features=5000, min_df=2,\n",
    "                      tokenizer=tokenizer, norm='l1',\n",
    "                      token_pattern=None, use_idf=False).fit(df['lemmas'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charming-reason",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_vocab = set(' '.join(small['lemmas']).split())\n",
    "print(small_vocab)\n",
    "vocab = vec.get_feature_names_out()\n",
    "small_vocab = sorted({v for v in small_vocab if v in vocab})\n",
    "print(small_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pharmaceutical-tower",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_x = vec.transform(small['lemmas']).toarray()\n",
    "features = list(vec.get_feature_names_out())\n",
    "idxs = [features.index(l) for l in small_vocab]\n",
    "rel_freq = pd.DataFrame(small_x[:, idxs], columns=small_vocab, index=['Rel. freq.'])\n",
    "rel_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norwegian-demographic",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer(max_features=5000, min_df=2,\n",
    "                      token_pattern=None,\n",
    "                      tokenizer=tokenizer, use_idf=True).fit(df['lemmas'])\n",
    "small_x = vec.transform(small['lemmas']).toarray()\n",
    "features = list(vec.get_feature_names_out())\n",
    "idxs = [features.index(l) for l in small_vocab]\n",
    "tfidf = pd.DataFrame(small_x[:, idxs], columns=small_vocab, index=['TF-IDF'])\n",
    "tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coated-projection",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_x = vec.transform(small['rhyme']).toarray()\n",
    "rhyme = pd.DataFrame(small_x[:, idxs], columns=small_vocab, index=['Enkel rijm'])\n",
    "rhyme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reverse-finland",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_x = vec.transform(small['lemmas']).toarray() + .15 * vec.transform(small['rhyme']).toarray()\n",
    "rhyme_weight = pd.DataFrame(small_x[:, idxs], columns=small_vocab, index=['Gewicht rijmwoorden (.15)'])\n",
    "rhyme_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sorted-qualification",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.concat((rel_freq, tfidf, rhyme, rhyme_weight))\n",
    "table.to_excel('../figures/Tab3.xlsx', index=True, header=True)\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weird-wedding",
   "metadata": {},
   "source": [
    "#### Comparison of verses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fde74e",
   "metadata": {},
   "source": [
    "We retrieve the indices of the verse lines in our example in the paper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ef7500",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_indices = []\n",
    "\n",
    "for v in ('Noch bi nachte noch bi daghe / Dats pine teghen spoet',\n",
    "          'Maer dat was pine jegen spoet / Al haddemen hem gegeven alt goet',\n",
    "          'Mar dat was pine ieghen spoet / Die hare ghegheuen hadde alt goet',\n",
    "          'Maer dat was pine jegen spoet / Die porte hen nieman daer ontoet'):\n",
    "    ex_indices.append((df['tokens'] == v).idxmax())\n",
    "\n",
    "ex_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elementary-medicare",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = df.loc[ex_indices]\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compound-buffalo",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_x = vec.transform(targets['lemmas']).toarray() + .15 * vec.transform(targets['rhyme']).toarray()\n",
    "distances = squareform(pdist(small_x, metric='cosine'))\n",
    "np.fill_diagonal(distances, np.nan)\n",
    "distances[np.triu_indices(4)] = np.nan\n",
    "labels = targets['tokens']\n",
    "labels = [l.replace(' / ', '\\n') for l in labels]\n",
    "labels = [f'{label}\\n({title})' for label, title in zip(labels, targets['title'])]\n",
    "distances = pd.DataFrame(distances, index=labels, columns=labels)\n",
    "distances = distances.iloc[1:, :-1]\n",
    "ax = sb.heatmap(distances, annot=True, cmap='Greys_r', cbar=False,\n",
    "                linewidths=1, linecolor='white', fmt='.5g')\n",
    "ax.tick_params(left=False, bottom=False)\n",
    "for l in plt.gca().lines:\n",
    "    l.set_alpha(0.3)\n",
    "plt.xticks(rotation=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{fig_dir}/Afb4.jpg', dpi=300);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thirty-lending",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.read_excel('../data/intertexts.xlsx')\n",
    "meta.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personalized-exclusion",
   "metadata": {},
   "source": [
    "Determine rhyme weight with no restrictions on vocabulary size, except for `min_df=2`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "identical-malawi",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer(max_features=None, min_df=2,\n",
    "                      tokenizer=tokenizer, token_pattern=None).fit(df['lemmas'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "listed-broadway",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall(df, meta, vec, rhyme_weight=.15):\n",
    "    titles = set(list(meta['source']) + list(meta['target']))\n",
    "    relevances, distances = [], []\n",
    "\n",
    "    for t1, t2 in product(titles, titles):\n",
    "        if t1 == t2:\n",
    "            continue\n",
    "\n",
    "        m = meta[meta['verse-length'] >= 2]\n",
    "        m = m[(m['source'] == t1) | (m['source'] == t2)]\n",
    "        m = m[(m['target'] == t1) | (m['target'] == t2)]\n",
    "\n",
    "        if not len(m):\n",
    "            continue\n",
    "\n",
    "        A = df[(~df['intertext'].isna()) & (df['title'] == t1)]\n",
    "        B = df[df['title'] == t2]\n",
    "\n",
    "        AX = vec.transform(A['lemmas']) + rhyme_weight * vec.transform(A['rhyme'])\n",
    "        BX = vec.transform(B['lemmas']) + rhyme_weight * vec.transform(B['rhyme'])\n",
    "\n",
    "        all_distances = pairwise_distances(AX, BX, metric='cosine')\n",
    "\n",
    "        for a_idx, (_, a) in enumerate(A.iterrows()):\n",
    "            distances.extend(all_distances[a_idx])\n",
    "            relevances.extend((B['intertext'] == a['intertext']).astype(int))\n",
    "    \n",
    "    return relevances, distances\n",
    "\n",
    "relevances, distances = precision_recall(df, meta, vec, rhyme_weight=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea6fe23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_curve_distances(y_true, distances):\n",
    "    y_true = np.array(y_true)\n",
    "    distances = np.array(distances)\n",
    "    \n",
    "    desc_score_indices = np.argsort(distances)\n",
    "    y_true = y_true[desc_score_indices]\n",
    "    distinct_value_indices = np.where(np.diff(distances[desc_score_indices]))[0]\n",
    "    threshold_idxs = np.r_[distinct_value_indices, y_true.size - 1]\n",
    "    \n",
    "    # Accumulate true positives and false positives\n",
    "    tps = np.cumsum(y_true)[threshold_idxs]\n",
    "    fps = 1 + threshold_idxs - tps\n",
    "    \n",
    "    precisions = tps / (tps + fps)\n",
    "    recalls = tps / tps[-1]\n",
    "    thresholds = distances[desc_score_indices][threshold_idxs]\n",
    "    \n",
    "    thresholds = thresholds[:-1]\n",
    "    precisions = precisions[:-1]\n",
    "    recalls = recalls[:-1]\n",
    "    \n",
    "    return precisions, recalls, thresholds\n",
    "\n",
    "precisions, recalls, thresholds = precision_recall_curve_distances(relevances, distances)\n",
    "f1s = (2 * precisions * recalls) / (precisions + recalls)\n",
    "max_f1_idx = np.array(f1s).argmax()\n",
    "max_f1 = f1s[max_f1_idx]\n",
    "max_f1_th = thresholds[max_f1_idx]\n",
    "\n",
    "print(f'Max(F1)={round(max_f1, 4)} voor afstand < {round(max_f1_th, 4)}')\n",
    "\n",
    "plt.plot(thresholds, precisions, label='precision', ls='dashed')\n",
    "plt.plot(thresholds, recalls, label='recall', ls='dotted')\n",
    "plt.plot(thresholds, f1s, label='F1', ls='solid')\n",
    "plt.axvline(max_f1_th, c='darkgrey', ls='--')\n",
    "plt.gca().set_xlabel('theta')\n",
    "plt.gca().legend()\n",
    "plt.title(f'max(f1)={round(max_f1, 4)} @ theta={round(max_f1_th, 4)}')\n",
    "plt.tight_layout();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "palestinian-debut",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame(zip(distances, relevances), columns=('distance', 'relevance'))\n",
    "res_df.boxplot('distance', 'relevance')\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "timely-click",
   "metadata": {},
   "source": [
    "### Calibrate parameters\n",
    "\n",
    "In this section, we have the code for experimenting with different hyperparameters of the system, so that we can calibrate it on the inventorized intertexts. We experimented with the:\n",
    "- additional weight for lemmas in verse-final, rhyme position;\n",
    "- the size of the vectorization vocabulary used;\n",
    "- the effect of TF-IDF (vs plain TF, which takes the relative frequencies of the lemmas at face value).\n",
    "\n",
    "##### 1. Rhyme weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ultimate-mixer",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "# also negative weight for demonstration purposes:\n",
    "rhyme_weights = tuple(np.linspace(-.3, 2.0, 50))\n",
    "\n",
    "for rhyme_weight in tqdm(rhyme_weights):\n",
    "    relevances, distances = precision_recall(df, meta, vec, rhyme_weight=rhyme_weight)\n",
    "    distances = 1 - np.array(distances) # take complement of distances\n",
    "    auc = roc_auc_score(relevances, distances)\n",
    "    av_prec = average_precision_score(relevances, distances)\n",
    "    scores.append((rhyme_weight, auc, av_prec))\n",
    "\n",
    "scores = pd.DataFrame(scores, columns=('rhyme weight', 'AUC', 'AV-PREC'))\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=(8, 7))\n",
    "\n",
    "# AUC plot\n",
    "scores.plot('rhyme weight', 'AUC', ax=ax1, legend=False)\n",
    "ax1.axvline(0, ls='-.', c='grey')\n",
    "ax1.axvline(scores.iloc[scores['AUC'].idxmax()]['rhyme weight'], ls='--', c='grey')\n",
    "ax1.set_title('Area Under Curve (AUC)')\n",
    "\n",
    "# Average Precision plot\n",
    "scores.plot('rhyme weight', 'AV-PREC', ax=ax2, legend=False)\n",
    "ax2.axvline(0, ls='-.', c='grey')\n",
    "ax2.axvline(scores.iloc[scores['AV-PREC'].idxmax()]['rhyme weight'], ls='--', c='grey')\n",
    "ax2.set_title('Average Precision')\n",
    "\n",
    "plt.xlabel('Gewicht lemmata in rijmpositie')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{fig_dir}/Afb5.jpg')\n",
    "\n",
    "optim_rw = scores.iloc[scores['AUC'].idxmax()]['rhyme weight']\n",
    "print('optimal rhyme weight:', optim_rw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hourly-active",
   "metadata": {},
   "source": [
    "##### 2. Vocabulary size (and TF vs TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "planned-summit",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer(tokenizer=tokenizer, token_pattern=None,\n",
    "                      min_df=2, max_features=None).fit(df['lemmas'])\n",
    "print('Maximum vocab size:', len(vec.get_feature_names_out()))\n",
    "\n",
    "scores = []\n",
    "\n",
    "vocab_sizes = list(range(500, 41000, 500))\n",
    "parametrizations = {\n",
    "                    'TF-IDF': {'min_df': 2},\n",
    "                    'TF': {'use_idf': False, 'min_df': 2},\n",
    "                    }\n",
    "\n",
    "for vocab_size in tqdm(vocab_sizes):\n",
    "    for param_name, param in parametrizations.items():\n",
    "        param['max_features'] = vocab_size\n",
    "        vec = TfidfVectorizer(tokenizer=tokenizer, token_pattern=None, **param)\n",
    "        vec.fit(df['lemmas'])\n",
    "        relevances, distances = precision_recall(df, meta, vec, rhyme_weight=optim_rw)\n",
    "        distances = 1 - np.array(distances)\n",
    "        auc = roc_auc_score(relevances, distances)\n",
    "        av_prec = average_precision_score(relevances, distances)\n",
    "        scores.append((param_name, vocab_size, auc, av_prec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8806e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.DataFrame(scores, columns=('param', 'vocab_size', 'AUC', 'AV-PREC'))\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=(8, 7))\n",
    "\n",
    "# For AV-PREC plot\n",
    "for i, (p, gr) in enumerate(scores.groupby('param')):\n",
    "    linestyle = ':' if i == 0 else '-'  # dotted for first group, solid for others\n",
    "    gr.plot('vocab_size', 'AV-PREC', label=p, ax=ax1, linestyle=linestyle)\n",
    "ax1.set_title('AV-PREC')\n",
    "\n",
    "# For AUC plot\n",
    "for i, (p, gr) in enumerate(scores.groupby('param')):\n",
    "    linestyle = ':' if i == 0 else '-'  # dotted for first group, solid for others\n",
    "    gr.plot('vocab_size', 'AUC', label=p, ax=ax2, linestyle=linestyle)\n",
    "ax2.set_title('AUC')\n",
    "\n",
    "plt.xlabel('Aantal lemmata in vocabularium')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{fig_dir}/Afb6.jpg', dpi=300);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5647f707",
   "metadata": {},
   "source": [
    "We use the product of the two scores, Area-Under-the-Curve (AUC) and average precision, to select the optimal vocabulary size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biblical-possible",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores['comb'] = scores['AUC'] * scores['AV-PREC']\n",
    "optim_vs = scores.iloc[scores['AUC'].idxmax()]\n",
    "display(optim_vs)\n",
    "optim_vs = optim_vs['vocab_size']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limiting-shame",
   "metadata": {},
   "source": [
    "## Final threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f8b89e",
   "metadata": {},
   "source": [
    "After optimizing the three parameter's in the previous section, we can now the optimal threshold value for determining (in a pragmatic, binary fashion) whether or not a combination of two verse groups might be an \"intertext\". To set this value, we vary the threshold between 0 and 1 and determine the distance where the trade-off betwene precision and recall is maximized, as reflected in the F1-score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coated-entertainment",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer(max_features=optim_vs, min_df=2,\n",
    "                      tokenizer=tokenizer, token_pattern=None).fit(df['lemmas'])\n",
    "\n",
    "relevances, distances = precision_recall(df, meta, vec, rhyme_weight=optim_rw)\n",
    "precisions, recalls, thresholds = precision_recall_curve_distances(relevances, distances)\n",
    "\n",
    "f1s = (2 * precisions * recalls) / (precisions + recalls)\n",
    "max_f1_idx = np.array(f1s).argmax()\n",
    "max_f1 = f1s[max_f1_idx]\n",
    "max_f1_th = thresholds[max_f1_idx]\n",
    "\n",
    "print(f'Max(F1)={round(max_f1, 4)} voor afstand < {round(max_f1_th, 4)}')\n",
    "\n",
    "plt.plot(thresholds, precisions, label='precision', ls='dashed')\n",
    "plt.plot(thresholds, recalls, label='recall', ls='dotted')\n",
    "plt.plot(thresholds, f1s, label='F1', ls='solid')\n",
    "plt.axvline(max_f1_th, c='darkgrey', ls='--')\n",
    "plt.gca().set_xlabel('distance')\n",
    "plt.gca().legend()\n",
    "plt.title(f'max(f1)={round(max_f1, 4)} @ distance={round(max_f1_th, 4)}')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{fig_dir}/Afb7.jpg', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208fdaca",
   "metadata": {},
   "source": [
    "So, to sum up, according to the calibration, the following system parameters were found to be optimal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc91af8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('optim_vs =', optim_vs)\n",
    "print('optim_rw =', optim_rw)\n",
    "print('optim_th =', max_f1_th)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21f2866",
   "metadata": {},
   "source": [
    "### Nearest neighbors\n",
    "\n",
    "The code block below generates the table with the $n$ most similar verse groups between *Moriaen* and *Lantsloot*. This example was used for the qualitative inspection of the results of the calibrated system. Note that we ignore hits if one of the passages contained 2+ proper nouns, which typically yielded uninteresting results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b1020a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_verses(title1, title2, base_df, vectorizer, prop_filt=2, rhyme_weight=.15):\n",
    "    A = base_df[base_df['title'] == title1]\n",
    "    B = base_df[base_df['title'] == title2]\n",
    "    \n",
    "    AX = vec.transform(A['lemmas']) + rhyme_weight * vec.transform(A['rhyme'])\n",
    "    BX = vec.transform(B['lemmas']) + rhyme_weight * vec.transform(B['rhyme'])\n",
    "    \n",
    "    nearest = []\n",
    "    for i, ax in enumerate(AX):\n",
    "        distances = pairwise_distances(ax, BX, metric='cosine').flatten()\n",
    "        top_i = distances.argsort()[0]\n",
    "        nearest.append((A.iloc[i]['tokens'], B.iloc[top_i]['tokens'],\n",
    "                        A.iloc[i]['lemmas'], B.iloc[top_i]['lemmas'],\n",
    "                        A.iloc[i]['title'], B.iloc[top_i]['title'],\n",
    "                        A.iloc[i]['intertext'], B.iloc[top_i]['intertext'],\n",
    "                        distances[top_i]))\n",
    "\n",
    "    nearest = pd.DataFrame(nearest,\n",
    "                           columns=['tokens1', 'tokens2', 'lemmas1', 'lemmas2',\n",
    "                                    'title1', 'title2', 'intertext1', 'intertext2',\n",
    "                                    'distance'])\n",
    "\n",
    "    nearest = nearest[nearest['title1'] != nearest['title2']]\n",
    "    nearest = nearest[\n",
    "                      (nearest['lemmas1'].str.count('n\\\\(prop\\\\)') < prop_filt) & \\\n",
    "                      (nearest['lemmas2'].str.count('n\\\\(prop\\\\)') < prop_filt) \n",
    "                     ]\n",
    "    return nearest\n",
    "\n",
    "nearest_df = nearest_verses('Moriaen', 'Lantsloot van der Haghedochte',\n",
    "                            base_df=df, vectorizer=vec, prop_filt=2)\n",
    "nearest_df = nearest_df.sort_values(by='distance')\n",
    "nearest_df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3234f2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_df = nearest_df.head(10)[['tokens1', 'tokens2', 'intertext1', 'intertext2', 'distance']]\n",
    "table_df.columns = ['Moriaen', 'Lantsloot', 'intertext1', 'intertext2', 'distance']\n",
    "table_df.to_excel('../figures/Tab4.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mdu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
