{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import glob\n",
    "import html\n",
    "import shutil\n",
    "\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LACUNA = re.compile(r'\\.\\.+')\n",
    "\n",
    "def load_file(path):\n",
    "    with open(path) as f:\n",
    "        xml_text = f.read()\n",
    "    \n",
    "    xml_text = xml_text.replace('&oudpond;', '')\n",
    "    xml_text = xml_text.replace('&supm;', 'm')\n",
    "    xml_text = xml_text.replace('&supM;', 'm')\n",
    "    xml_text = xml_text.replace('&supc;', 'c')\n",
    "    xml_text = xml_text.replace('&supt;', 't')\n",
    "    xml_text = xml_text.replace('&supn;', 'n')\n",
    "    xml_text = xml_text.replace('&sups;', 's')\n",
    "    xml_text = xml_text.replace('&supd;', 'd')\n",
    "    xml_text = xml_text.replace('&supc;', 'c')\n",
    "    xml_text = xml_text.replace('&uring;', 'u')\n",
    "    xml_text = xml_text.replace('&lt;', '')\n",
    "    xml_text = xml_text.replace('&gt;', '')\n",
    "    xml_text = html.unescape(xml_text)\n",
    "\n",
    "    soup = BeautifulSoup(xml_text)\n",
    "    \n",
    "    data = {}\n",
    "\n",
    "    # extract metadata:\n",
    "    data['id'] = os.path.basename(path).replace('.xml', '')\n",
    "    data['title'] = soup.find('title').text\n",
    "    data['author'] = soup.find('author').text\n",
    "    \n",
    "    postquem = '<UNK>'\n",
    "    try:\n",
    "        postquem = soup.find('interpgrp', {'type': 'witnessYear_from'})\n",
    "        postquem = postquem.find('interp')['value']\n",
    "    except AttributeError:\n",
    "        pass\n",
    "    \n",
    "    antequem = '<UNK>'\n",
    "    try:\n",
    "        antequem = soup.find('interpgrp', {'type': 'witnessYear_to'})\n",
    "        antequem = antequem.find('interp')['value']\n",
    "    except AttributeError:\n",
    "        pass\n",
    "    \n",
    "    data['date'] = f'{postquem}-{antequem}'\n",
    "    \n",
    "    provenance = '<UNK>'\n",
    "    try:\n",
    "        provenance = soup.find('interpgrp', {'type': 'corpusProvenance'})\n",
    "        provenance = provenance.find('interp')['value']\n",
    "    except AttributeError:\n",
    "        pass\n",
    "    data['provenance'] = provenance\n",
    "    \n",
    "    # extract and clean lines:\n",
    "    lines = []\n",
    "    for line in soup.find_all('l'):\n",
    "        text = line.get_text().strip()\n",
    "        if text and not re.search(LACUNA, text):\n",
    "            line = ''.join([c for c in text if c.isalpha() or c.isspace()]).strip()\n",
    "            if line:\n",
    "                lines.append(line)\n",
    "    \n",
    "    data['lines'] = lines\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "for fn in tqdm(glob.glob('../data/cdrom_rhyme/*.xml')):\n",
    "    texts.append(load_file(fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fn in tqdm(glob.glob('../data/cdrom_CG1/*.xml')):\n",
    "    with open(fn) as f:\n",
    "        text = f.read()\n",
    "    \n",
    "    # metadata\n",
    "    data = {}\n",
    "    data['id'] = os.path.basename(fn).replace('.xml', '')\n",
    "    data['title'] = re.findall(r'\\<bron_oms\\>(.*)\\<\\/bron_oms\\>', text)[0]\n",
    "    postquem = re.findall(r\"jaar\\_tot\\=\\'([0-9]+)'\", text)[0]\n",
    "    antequem = re.findall(r\"jaar\\_van\\=\\'([0-9]+)'\", text)[0]\n",
    "    data['date'] = f'{postquem}-{antequem}'\n",
    "    \n",
    "    data['provenance'] = 'CG1'\n",
    "    data['author'] = 'Onbekend'\n",
    "    \n",
    "    lines = []\n",
    "    for line in text.split('\\n'):\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        line = line.replace('<A >', '').replace('</A>', '')\n",
    "        if not line or re.search(LACUNA, line):\n",
    "            continue\n",
    "        \n",
    "        clean = ''\n",
    "        for word in re.findall(r'<C ([0-9#\\*@\\+]+)_([^>]+)>\\s*([^ \\n\\t\\r<]+)', line):\n",
    "            word = word[-1]\n",
    "            word = ''.join([c for c in word if c.isalpha() or c.isspace()]).strip()\n",
    "            if word:\n",
    "                clean += word + ' '\n",
    "        clean = clean.strip()\n",
    "        if clean:\n",
    "            lines.append(clean)\n",
    "    \n",
    "    data['lines'] = lines\n",
    "    \n",
    "    texts.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = []\n",
    "for text in texts:\n",
    "    d = {d:text[d] for d in text if d != 'lines'}\n",
    "    metadata.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf = pd.DataFrame(metadata)\n",
    "mdf = mdf.set_index('id')\n",
    "mdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up author labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "mdf['author'] = mdf['author'].replace('Niet van toepassing', 'Onbekend')\n",
    "mdf['author'] = mdf['author'].replace('Onbekend', np.nan)\n",
    "mdf['author'] = mdf['author'].str.replace(r'Jacob van Maerlant\\?', 'Jacob van Maerlant(?)')\n",
    "mdf['author'].value_counts(dropna=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set some (uninformative) values for missing dates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf.loc['jan_splinters_testament', 'date'] = '1550-1550'\n",
    "mdf.loc['borchgrave_van_couchi_fragm_dp', 'date'] = '1300-1325'\n",
    "mdf.loc['grimbergse_oorlog', 'date'] = '1300-1350'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf['date_range'] = mdf['date']\n",
    "dates = []\n",
    "for d in mdf['date_range']:\n",
    "    d1, d2 = [int(date_str) for date_str in d.split('-')]\n",
    "    d = d1 + ((d2 - d1) / 2)\n",
    "    dates.append(d)\n",
    "mdf['date'] = dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf['date'].plot.kde();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf['genre'] = None\n",
    "mdf['subgenre'] = None\n",
    "mdf.to_excel('../data/metadata_extract.xlsx', header=True, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enrich using PIE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taken from the [PIE NLP Taggers documentation](https://github.com/hipster-philology/nlp-pie-taggers):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from pie_extended.cli.utils import get_tagger, get_model, download\n",
    "import lxml.etree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_download = False # set to True if necessary\n",
    "if do_download:\n",
    "    for dl in download(\"dum\"):\n",
    "        x = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_path = '../data/xml'\n",
    "try:\n",
    "    shutil.rmtree(xml_path)\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "os.mkdir(xml_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pie_extended.models.dum.imports import get_iterator_and_processor\n",
    "from collections import defaultdict\n",
    "\n",
    "iterator, processor = get_iterator_and_processor()\n",
    "tagger = get_tagger('dum', batch_size=1024, device=\"cpu\", model_path=None)\n",
    "\n",
    "for text in tqdm(texts):\n",
    "    title = text['id']\n",
    "    root = lxml.etree.Element('text')\n",
    "    root.attrib['id'] = title\n",
    "    \n",
    "    lines: List[str] = [l for l in text['lines']]\n",
    "    for nb, line in enumerate(lines):\n",
    "        l_node = lxml.etree.Element('l')\n",
    "        l_node.attrib['n'] = str(nb + 1)\n",
    "        \n",
    "        for w in tagger.tag_str(line.lower(), iterator=iterator, processor=processor):\n",
    "            w_node = lxml.etree.Element('w')\n",
    "            for tag in ('form', 'lemma', 'pos'):\n",
    "                subnode = lxml.etree.Element(tag)\n",
    "                subnode.text = w[tag]\n",
    "                w_node.append(subnode)\n",
    "\n",
    "            l_node.append(w_node)\n",
    "            \n",
    "        l_node.attrib['tokens'] = text['lines'][nb]\n",
    "        root.append(l_node)\n",
    "    \n",
    "    with open(f'{xml_path}/{title}.xml', 'w') as f:\n",
    "        f.write(lxml.etree.tostring(root, xml_declaration=True,\n",
    "                                pretty_print=True, encoding='utf-8').decode())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (n36)",
   "language": "python",
   "name": "n36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
